{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interact\n",
    "\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interact\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import Dropout2d\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    " \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Normalize\n",
    "from torchinfo import summary\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "np.random.seed(0) \n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# path para guardar o dataset\n",
    "PATH = './'\n",
    "PATH_TRAIN_CSV = './data/train.csv'\n",
    "PATH_TRAIN_IMG = './data/train_data.mat'\n",
    "PATH_TEST_CSV = './data/test.csv'\n",
    "PATH_TEST_IMG = './data/test_data.mat'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Exploração e Preparação dos Dados\n",
    "\n",
    "### Visualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_mat(train_file,test_file):\n",
    "    train_mat = scipy.io.loadmat(train_file) \n",
    "    test_mat = scipy.io.loadmat(test_file) \n",
    "    # print(train_mat.keys())\n",
    "    # print(test_mat.keys())\n",
    "    train_np = np.array(train_mat['train_data']).transpose(2,0,1)\n",
    "    test_np = np.array(test_mat['test_data']).transpose(2,0,1)\n",
    "    # print(train_np.shape)\n",
    "    # print(test_np.shape)\n",
    "    return  train_np, test_np\n",
    "\n",
    "\n",
    "def load_data(path_train_csv, path_train_img, path_test_csv, path_test_img):\n",
    "    train_csv = pd.read_csv(path_train_csv, header=0)\n",
    "    test_csv = pd.read_csv(path_test_csv, header=0)\n",
    "    train_img, test_img = get_data_from_mat(path_train_img, path_test_img)\n",
    "    # train = train_csv + train_img\n",
    "    # test = test_csv + test_img\n",
    "    # return train, test\n",
    "    return train_csv, test_csv, train_img, test_img\n",
    "\n",
    "\n",
    "def visualize(image):\n",
    "    #plt.figure(\"sample\", (12, 6))\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image, cmap=\"gray\")    \n",
    "    #plt.subplot(1, 2, 2)\n",
    "    #plt.imshow(image, cmap=\"gray\")\n",
    "    plt.show()      \n",
    "\n",
    "def show_ds(ds):\n",
    "    print(\"ds shape:\",ds.shape)\n",
    "    print(\"ds max:\",np.max(ds))\n",
    "    print(\"ds min:\",np.min(ds))\n",
    "    print(\"ds average:\",np.average(ds))\n",
    "    @interact\n",
    "    def visualize_set(scan_index=(0,len(ds)-1)):\n",
    "        #print(scan_index)\n",
    "        visualize(ds[scan_index,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data de treino:\n",
      "      id  age  sex  education\n",
      "0      1   13    1          7\n",
      "1      2   14    0          8\n",
      "2      3   15    1          9\n",
      "3      4   15    1          9\n",
      "4      5   15    1          9\n",
      "..   ...  ...  ...        ...\n",
      "107  108   77    1          4\n",
      "108  109   67    0          4\n",
      "109  110   55    0          4\n",
      "110  111   76    1          3\n",
      "111  112   69    0          4\n",
      "\n",
      "[112 rows x 4 columns]\n",
      "ds shape: (112, 90, 90)\n",
      "ds max: 1.0\n",
      "ds min: 0.0\n",
      "ds average: 0.024116160549305543\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117b9e64669b425db52686add9028a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=55, description='scan_index', max=111), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data de Teste:\n",
      "    id  sex  education\n",
      "0    1    0         13\n",
      "1    2    0         11\n",
      "2    3    1          9\n",
      "3    4    1         13\n",
      "4    5    0         12\n",
      "5    6    0         17\n",
      "6    7    0          9\n",
      "7    8    0          4\n",
      "8    9    1          9\n",
      "9   10    1          4\n",
      "10  11    1         14\n",
      "11  12    0          9\n",
      "12  13    1          2\n",
      "13  14    1          5\n",
      "14  15    1          9\n",
      "15  16    1         11\n",
      "16  17    1          9\n",
      "17  18    0         17\n",
      "18  19    1         15\n",
      "19  20    1         14\n",
      "20  21    1          4\n",
      "21  22    0          4\n",
      "22  23    1          4\n",
      "23  24    0          0\n",
      "24  25    1          2\n",
      "25  26    1          4\n",
      "26  27    1          3\n",
      "27  28    1          4\n",
      "ds shape: (28, 90, 90)\n",
      "ds max: 1.0\n",
      "ds min: 0.0\n",
      "ds average: 0.024994026906171023\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e785f5c2964d979d9cc12cdad2f520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=13, description='scan_index', max=27), Output()), _dom_classes=('widget-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv, test_csv, train_img, test_img = load_data(PATH_TRAIN_CSV, PATH_TRAIN_IMG, PATH_TEST_CSV, PATH_TEST_IMG)\n",
    "\n",
    "print(\"Data de treino:\")\n",
    "print(train_csv)\n",
    "show_ds(train_img)\n",
    "print(\"Data de Teste:\")\n",
    "print(test_csv)\n",
    "show_ds(test_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_sex(csv):\n",
    "    female = csv['sex']\n",
    "    male = []\n",
    "    for person in female:\n",
    "        if person==1:\n",
    "            male.append(0)\n",
    "        else:\n",
    "            male.append(1)\n",
    "    csv.drop('sex', axis='columns', inplace=True)\n",
    "    csv['Female']=female\n",
    "    csv['Male']=male\n",
    "    return csv\n",
    "    \n",
    "def img_to_list(img):\n",
    "    tamanho = len(img)\n",
    "    lista = []\n",
    "    # triangular inferior sem diagonal\n",
    "    for linha in range(tamanho):\n",
    "        for coluna in range(linha):\n",
    "            lista.append(img[linha][coluna])\n",
    "    return lista\n",
    "\n",
    "def imgs_to_matrix(imgs):\n",
    "    matrix = []\n",
    "    for img in imgs:\n",
    "        matrix.append(img_to_list(img))\n",
    "    return matrix\n",
    "\n",
    "def remove_null_columns(matrix1, matrix2):\n",
    "    columns_to_remove = []\n",
    "    m1_row_len = len(matrix1)\n",
    "    m2_row_len = len(matrix2)\n",
    "    column_len = len(matrix1[0])\n",
    "    for column in range(column_len):\n",
    "        all_zero = True\n",
    "        for row in range(m1_row_len):\n",
    "            if matrix1[row][column]!=0:\n",
    "                all_zero=False\n",
    "        for row in range(m2_row_len):\n",
    "            if matrix2[row][column]!=0:\n",
    "                all_zero=False\n",
    "        if all_zero:\n",
    "            columns_to_remove.append(column)\n",
    "\n",
    "    brain_activity_index = list(range(column_len))\n",
    "    for column in columns_to_remove[::-1]:\n",
    "        brain_activity_index.pop(column)\n",
    "        for line in range(m1_row_len):\n",
    "            matrix1[line].pop(column)\n",
    "        for line in range(m2_row_len):\n",
    "            matrix2[line].pop(column)\n",
    "    return matrix1, matrix2, brain_activity_index\n",
    "\n",
    "def join_data(train_csv, test_csv, train_img, test_img):\n",
    "    train_matrix = imgs_to_matrix(train_img)\n",
    "    test_matrix = imgs_to_matrix(test_img)\n",
    "    train_clean_matrix, test_clean_matrix, brain_activity_index = remove_null_columns(train_matrix, test_matrix)\n",
    "    train_data  = pd.concat([train_csv, pd.DataFrame(train_clean_matrix)], axis=1)\n",
    "    train_data .columns = list(train_csv.columns) + [f'rel-{brain_activity_index[i]}' for i in range(len(brain_activity_index))]\n",
    "    test_data = pd.concat([test_csv, pd.DataFrame(test_clean_matrix)], axis=1)\n",
    "    test_data.columns = list(test_csv.columns) + [f'rel-{brain_activity_index[i]}' for i in range(len(brain_activity_index))]\n",
    "    return train_data , test_data, brain_activity_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  age  education  Female  Male     rel-1  rel-3     rel-4     rel-5   \n",
      "0      1   13          7       1     0  0.131525    0.0  0.136950  0.000000  \\\n",
      "1      2   14          8       0     1  0.117704    0.0  0.132998  0.037714   \n",
      "2      3   15          9       1     0  0.155806    0.0  0.165429  0.022278   \n",
      "3      4   15          9       1     0  0.145214    0.0  0.162493  0.000000   \n",
      "4      5   15          9       1     0  0.161360    0.0  0.172043  0.017686   \n",
      "..   ...  ...        ...     ...   ...       ...    ...       ...       ...   \n",
      "107  108   77          4       1     0  0.215767    0.0  0.184942  0.019446   \n",
      "108  109   67          4       0     1  0.143005    0.0  0.124350  0.000000   \n",
      "109  110   55          4       0     1  0.116085    0.0  0.156406  0.020947   \n",
      "110  111   76          3       1     0  0.156654    0.0  0.166613  0.046464   \n",
      "111  112   69          4       0     1  0.114586    0.0  0.128877  0.045583   \n",
      "\n",
      "        rel-8  ...  rel-3975  rel-3977  rel-3979  rel-3981  rel-3989   \n",
      "0    0.146309  ...  0.000000  0.000000  0.000000  0.014927  0.000000  \\\n",
      "1    0.113425  ...  0.000000  0.000000  0.000000  0.031811  0.000000   \n",
      "2    0.096080  ...  0.000000  0.000000  0.000000  0.021235  0.018050   \n",
      "3    0.124115  ...  0.000000  0.000000  0.000000  0.015130  0.000000   \n",
      "4    0.099488  ...  0.000000  0.000000  0.000000  0.016533  0.000000   \n",
      "..        ...  ...       ...       ...       ...       ...       ...   \n",
      "107  0.109972  ...  0.033167  0.015108  0.016434  0.056483  0.000000   \n",
      "108  0.090189  ...  0.000000  0.013166  0.029519  0.051964  0.000000   \n",
      "109  0.122589  ...  0.000000  0.000000  0.000000  0.034193  0.010498   \n",
      "110  0.091244  ...  0.000000  0.000000  0.000000  0.051497  0.012697   \n",
      "111  0.124734  ...  0.000000  0.000000  0.045683  0.028919  0.000000   \n",
      "\n",
      "     rel-3993  rel-3997  rel-3999  rel-4001  rel-4003  \n",
      "0    0.000000  0.000000  0.000000  0.585006  0.280606  \n",
      "1    0.000000  0.000000  0.000000  0.599437  0.207478  \n",
      "2    0.000000  0.000000  0.000000  0.630374  0.246472  \n",
      "3    0.000000  0.000000  0.000000  0.562505  0.287888  \n",
      "4    0.000000  0.000000  0.000000  0.564043  0.234284  \n",
      "..        ...       ...       ...       ...       ...  \n",
      "107  0.000000  0.000000  0.011150  0.660292  0.302675  \n",
      "108  0.013098  0.011171  0.019141  0.630415  0.204125  \n",
      "109  0.000000  0.000000  0.000000  0.574355  0.246784  \n",
      "110  0.019894  0.010225  0.000000  0.631057  0.216259  \n",
      "111  0.000000  0.024996  0.000000  0.655354  0.274812  \n",
      "\n",
      "[112 rows x 1207 columns]\n",
      "    id  education  Female  Male     rel-1     rel-3     rel-4     rel-5   \n",
      "0    1         13       0     1  0.140891  0.000000  0.158141  0.034232  \\\n",
      "1    2         11       0     1  0.147297  0.000000  0.155310  0.022638   \n",
      "2    3          9       1     0  0.091724  0.000000  0.117124  0.036960   \n",
      "3    4         13       1     0  0.095972  0.000000  0.139443  0.043691   \n",
      "4    5         12       0     1  0.129573  0.000000  0.156720  0.014294   \n",
      "5    6         17       0     1  0.142985  0.000000  0.183126  0.036850   \n",
      "6    7          9       0     1  0.131228  0.000000  0.175776  0.089642   \n",
      "7    8          4       0     1  0.101044  0.000000  0.133913  0.122353   \n",
      "8    9          9       1     0  0.230942  0.000000  0.301362  0.074309   \n",
      "9   10          4       1     0  0.134479  0.000000  0.213318  0.056141   \n",
      "10  11         14       1     0  0.189829  0.000000  0.204577  0.010921   \n",
      "11  12          9       0     1  0.185456  0.000000  0.168654  0.000000   \n",
      "12  13          2       1     0  0.134865  0.000000  0.145524  0.048349   \n",
      "13  14          5       1     0  0.108800  0.000000  0.153185  0.022882   \n",
      "14  15          9       1     0  0.159263  0.000000  0.158870  0.035078   \n",
      "15  16         11       1     0  0.181882  0.000000  0.250783  0.027103   \n",
      "16  17          9       1     0  0.173154  0.000000  0.141448  0.000000   \n",
      "17  18         17       0     1  0.139383  0.000000  0.189371  0.033366   \n",
      "18  19         15       1     0  0.135308  0.000000  0.142088  0.011406   \n",
      "19  20         14       1     0  0.117093  0.000000  0.135168  0.000000   \n",
      "20  21          4       1     0  0.203059  0.018586  0.180570  0.104014   \n",
      "21  22          4       0     1  0.084421  0.000000  0.154965  0.034056   \n",
      "22  23          4       1     0  0.192080  0.000000  0.210771  0.083894   \n",
      "23  24          0       0     1  0.154142  0.000000  0.168493  0.000000   \n",
      "24  25          2       1     0  0.227324  0.000000  0.231086  0.010481   \n",
      "25  26          4       1     0  0.179663  0.013680  0.163752  0.085185   \n",
      "26  27          3       1     0  0.193464  0.000000  0.251571  0.056901   \n",
      "27  28          4       1     0  0.122592  0.000000  0.164023  0.050183   \n",
      "\n",
      "       rel-8    rel-13  ...  rel-3975  rel-3977  rel-3979  rel-3981  rel-3989   \n",
      "0   0.125302  0.100274  ...  0.000000  0.000000  0.000000  0.000000  0.000000  \\\n",
      "1   0.137629  0.092260  ...  0.000000  0.000000  0.000000  0.013910  0.000000   \n",
      "2   0.116989  0.104919  ...  0.000000  0.000000  0.000000  0.047666  0.010004   \n",
      "3   0.087918  0.126898  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4   0.095124  0.119225  ...  0.000000  0.000000  0.000000  0.015233  0.000000   \n",
      "5   0.091377  0.087207  ...  0.000000  0.000000  0.000000  0.010627  0.000000   \n",
      "6   0.123222  0.104854  ...  0.000000  0.000000  0.020643  0.036057  0.000000   \n",
      "7   0.108414  0.111986  ...  0.000000  0.000000  0.011329  0.023783  0.010706   \n",
      "8   0.065176  0.172441  ...  0.013943  0.040184  0.041840  0.039660  0.000000   \n",
      "9   0.084780  0.092307  ...  0.010035  0.000000  0.000000  0.013395  0.018347   \n",
      "10  0.111955  0.137713  ...  0.059839  0.000000  0.000000  0.086756  0.000000   \n",
      "11  0.120459  0.099187  ...  0.000000  0.000000  0.016020  0.024357  0.021780   \n",
      "12  0.101788  0.091091  ...  0.000000  0.022555  0.010633  0.029756  0.012671   \n",
      "13  0.088783  0.098697  ...  0.000000  0.000000  0.000000  0.018988  0.000000   \n",
      "14  0.107662  0.067334  ...  0.000000  0.000000  0.000000  0.057889  0.000000   \n",
      "15  0.105886  0.089768  ...  0.000000  0.000000  0.000000  0.049957  0.000000   \n",
      "16  0.087167  0.074704  ...  0.000000  0.000000  0.000000  0.017929  0.000000   \n",
      "17  0.101199  0.095522  ...  0.000000  0.000000  0.000000  0.030575  0.000000   \n",
      "18  0.133902  0.110800  ...  0.000000  0.000000  0.000000  0.017787  0.000000   \n",
      "19  0.088000  0.067355  ...  0.000000  0.000000  0.000000  0.050251  0.000000   \n",
      "20  0.126438  0.083578  ...  0.000000  0.017215  0.016428  0.023965  0.018130   \n",
      "21  0.127228  0.099905  ...  0.000000  0.017495  0.000000  0.091617  0.000000   \n",
      "22  0.110031  0.134561  ...  0.013666  0.042774  0.000000  0.126271  0.000000   \n",
      "23  0.094874  0.081863  ...  0.000000  0.000000  0.000000  0.033486  0.000000   \n",
      "24  0.099137  0.135413  ...  0.023205  0.000000  0.011331  0.088008  0.019708   \n",
      "25  0.160272  0.098753  ...  0.000000  0.000000  0.000000  0.075546  0.024103   \n",
      "26  0.112662  0.122816  ...  0.000000  0.016901  0.011435  0.048129  0.011214   \n",
      "27  0.085027  0.061122  ...  0.000000  0.000000  0.000000  0.025536  0.000000   \n",
      "\n",
      "    rel-3993  rel-3997  rel-3999  rel-4001  rel-4003  \n",
      "0   0.000000  0.000000  0.000000  0.612109  0.193069  \n",
      "1   0.000000  0.000000  0.000000  0.635466  0.275949  \n",
      "2   0.000000  0.000000  0.000000  0.577096  0.260915  \n",
      "3   0.000000  0.000000  0.000000  0.535117  0.198058  \n",
      "4   0.000000  0.000000  0.000000  0.590000  0.266638  \n",
      "5   0.000000  0.000000  0.000000  0.702736  0.267522  \n",
      "6   0.000000  0.000000  0.000000  0.612072  0.282661  \n",
      "7   0.000000  0.000000  0.014537  0.611550  0.291660  \n",
      "8   0.000000  0.011865  0.000000  0.608007  0.278882  \n",
      "9   0.013312  0.024165  0.000000  0.633834  0.284398  \n",
      "10  0.000000  0.010140  0.000000  0.662728  0.312695  \n",
      "11  0.000000  0.021331  0.018617  0.674813  0.441362  \n",
      "12  0.000000  0.000000  0.000000  0.583719  0.292009  \n",
      "13  0.000000  0.000000  0.000000  0.600286  0.286279  \n",
      "14  0.000000  0.000000  0.000000  0.555549  0.204871  \n",
      "15  0.000000  0.000000  0.000000  0.589784  0.310762  \n",
      "16  0.000000  0.000000  0.000000  0.576170  0.248499  \n",
      "17  0.000000  0.000000  0.000000  0.670338  0.232758  \n",
      "18  0.000000  0.000000  0.000000  0.646140  0.276538  \n",
      "19  0.000000  0.000000  0.000000  0.640091  0.320452  \n",
      "20  0.020956  0.000000  0.010584  0.684640  0.240465  \n",
      "21  0.000000  0.000000  0.016944  0.640797  0.249482  \n",
      "22  0.000000  0.000000  0.000000  0.654685  0.250583  \n",
      "23  0.000000  0.000000  0.047760  0.632460  0.325999  \n",
      "24  0.000000  0.011046  0.000000  0.693522  0.217447  \n",
      "25  0.000000  0.000000  0.000000  0.673725  0.213339  \n",
      "26  0.015723  0.000000  0.012270  0.602484  0.222229  \n",
      "27  0.000000  0.014708  0.000000  0.596880  0.259705  \n",
      "\n",
      "[28 rows x 1206 columns]\n"
     ]
    }
   ],
   "source": [
    "train_csv = fix_sex(train_csv)\n",
    "test_csv = fix_sex(test_csv)\n",
    "train_data, test_data, brain_activity_index = join_data(train_csv, test_csv, train_img, test_img)\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Definir o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNNModel_2                               [32, 10]                  --\n",
      "├─Sequential: 1-1                        [32, 16, 13, 13]          --\n",
      "│    └─Conv2d: 2-1                       [32, 16, 26, 26]          160\n",
      "│    └─ReLU: 2-2                         [32, 16, 26, 26]          --\n",
      "│    └─MaxPool2d: 2-3                    [32, 16, 13, 13]          --\n",
      "├─Sequential: 1-2                        [32, 32, 5, 5]            --\n",
      "│    └─Conv2d: 2-4                       [32, 32, 11, 11]          4,640\n",
      "│    └─ReLU: 2-5                         [32, 32, 11, 11]          --\n",
      "│    └─MaxPool2d: 2-6                    [32, 32, 5, 5]            --\n",
      "├─Linear: 1-3                            [32, 10]                  8,010\n",
      "==========================================================================================\n",
      "Total params: 12,810\n",
      "Trainable params: 12,810\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 21.68\n",
      "==========================================================================================\n",
      "Input size (MB): 0.10\n",
      "Forward/backward pass size (MB): 3.76\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 3.91\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNNModel_4                               [32, 10]                  --\n",
      "├─Sequential: 1-1                        [32, 32, 12, 12]          --\n",
      "│    └─Conv2d: 2-1                       [32, 32, 24, 24]          832\n",
      "│    └─BatchNorm2d: 2-2                  [32, 32, 24, 24]          64\n",
      "│    └─ReLU: 2-3                         [32, 32, 24, 24]          --\n",
      "│    └─MaxPool2d: 2-4                    [32, 32, 12, 12]          --\n",
      "│    └─Dropout2d: 2-5                    [32, 32, 12, 12]          --\n",
      "├─Linear: 1-2                            [32, 128]                 589,952\n",
      "├─Linear: 1-3                            [32, 10]                  1,290\n",
      "==========================================================================================\n",
      "Total params: 592,138\n",
      "Trainable params: 592,138\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 34.26\n",
      "==========================================================================================\n",
      "Input size (MB): 0.10\n",
      "Forward/backward pass size (MB): 9.47\n",
      "Params size (MB): 2.37\n",
      "Estimated Total Size (MB): 11.94\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# CNN Model2: Sequential (Conv, ReLU, MaxPool), Sequential, Linear\n",
    "class CNNModel_2(Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel_2, self).__init__()\n",
    "        self.layer1 = Sequential(Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=0),\n",
    "                                 ReLU(),\n",
    "                                 MaxPool2d(kernel_size=2)\n",
    "                                )\n",
    "        self.layer2 = Sequential(Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0),\n",
    "                                 ReLU(),\n",
    "                                 MaxPool2d(kernel_size=2)\n",
    "                                )       \n",
    "        self.fc1 = Linear(in_features=32 * 5 * 5, out_features=10)  # Fully connected 1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1) #Flatten\n",
    "        out = self.fc1(out) #Dense\n",
    "        return out\n",
    "    \n",
    "model = CNNModel_2()\n",
    "print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0)) #verbose=2 Show weight and bias layers in full detail\n",
    "    \n",
    "# CNN Model4: Sequential (Conv, BatchNorm, ReLU, MaxPool, Dropout), Linear, Linear\n",
    "class CNNModel_4(Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel_4, self).__init__()\n",
    "        self.layer1 = Sequential(nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=0),\n",
    "                                    BatchNorm2d(32),\n",
    "                                    ReLU(),\n",
    "                                    MaxPool2d(2),\n",
    "                                    Dropout2d(0.2)\n",
    "                                    )\n",
    "        self.fc1 = Linear(in_features=32*12*12, out_features=128) # 16928\n",
    "        self.fc2 = Linear(in_features=128, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = CNNModel_4()\n",
    "print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0)) #verbose=2 Show weight and bias layers in full detail"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Treinar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(h5_file, train_dl, val_dl, model, criterion, optimizer):\n",
    "    liveloss = PlotLosses()\n",
    "    for epoch in range(EPOCHS):\n",
    "        logs = {} # para o livelossplot\n",
    "        # Train phase\n",
    "        model.train() \n",
    "        running_loss  = 0.0\n",
    "        running_corrects  = 0.0\n",
    "        for batch_i, (inputs, labels) in enumerate(train_dl): \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.detach() * inputs.size(0)\n",
    "            #acc = accuracy_score(labels.numpy(), np.argmax(outputs.detach().numpy(), axis=1))\n",
    "            _, preds = torch.max(outputs, 1) # Get predictions from the maximum value\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(train_dl.dataset)\n",
    "        epoch_acc = running_corrects.float() / len(train_dl.dataset)\n",
    "        logs['loss'] = epoch_loss.item()\n",
    "        logs['accuracy'] = epoch_acc.item()\n",
    "            \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss  = 0.0\n",
    "        running_corrects  = 0.0\n",
    "        for inputs, labels in val_dl: \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.detach() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1) # Get predictions from the maximum value\n",
    "            #acc = accuracy_score(labels.numpy(), np.argmax(outputs.detach().numpy(), axis=1))\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(val_dl.dataset)\n",
    "        epoch_acc = running_corrects.float() / len(val_dl.dataset)\n",
    "        logs['val_loss'] = epoch_loss.item()\n",
    "        logs['val_accuracy'] = epoch_acc.item()\n",
    "        #print(f'Epoch {epoch:03}: | Loss: {epoch_loss/len(train_dl):.5f} | Acc: {epoch_acc/len(train_dl):.3f}')      \n",
    "        liveloss.update(logs)\n",
    "        liveloss.send()\n",
    "    torch.save(model,h5_file) # para gravar o modelo no final do treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CNNModel_2 ################\n",
    "model = CNNModel_2()\n",
    "model.cuda()\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treino do modelo CNNModel_2\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "criterion = CrossEntropyLoss() # neste caso implementa a sparse_categorical_crossentropy #nn.CrossEntropyLoss accepts ground truth labels directly as integers #in [0, N_CLASSES[ (no need to onehot encode the labels)\n",
    "optimizer = SGD(model.parameters(), lr=LEARNING_RATE) \n",
    "#optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "starttime = time.perf_counter()\n",
    "train_model('CNNModel_2.pth', train_dl, val_dl, model, criterion, optimizer)\n",
    "endtime = time.perf_counter()\n",
    "print(f\"Tempo gasto: {endtime - starttime} segundos\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Avaliar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Testar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
