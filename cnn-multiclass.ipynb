{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ciara\\Desktop\\imag-deep-learning\\cnn-multiclass.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ciara/Desktop/imag-deep-learning/cnn-multiclass.ipynb#W1sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlivelossplot\u001b[39;00m \u001b[39mimport\u001b[39;00m PlotLosses\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ciara/Desktop/imag-deep-learning/cnn-multiclass.ipynb#W1sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m0\u001b[39m) \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ciara/Desktop/imag-deep-learning/cnn-multiclass.ipynb#W1sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m torch\u001b[39m.\u001b[39;49mmanual_seed(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ciara/Desktop/imag-deep-learning/cnn-multiclass.ipynb#W1sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ciara/Desktop/imag-deep-learning/cnn-multiclass.ipynb#W1sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m random\u001b[39m.\u001b[39mseed(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ciara\\anaconda3\\envs\\Monai\\lib\\site-packages\\torch\\random.py:40\u001b[0m, in \u001b[0;36mmanual_seed\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcuda\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_is_in_bad_fork():\n\u001b[1;32m---> 40\u001b[0m     torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mmanual_seed_all(seed)\n\u001b[0;32m     42\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmps\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mmps\u001b[39m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[1;32mc:\\Users\\ciara\\anaconda3\\envs\\Monai\\lib\\site-packages\\torch\\cuda\\random.py:113\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m    110\u001b[0m         default_generator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdefault_generators[i]\n\u001b[0;32m    111\u001b[0m         default_generator\u001b[39m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m--> 113\u001b[0m _lazy_call(cb, seed_all\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\ciara\\anaconda3\\envs\\Monai\\lib\\site-packages\\torch\\cuda\\__init__.py:183\u001b[0m, in \u001b[0;36m_lazy_call\u001b[1;34m(callable, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_lazy_call\u001b[39m(\u001b[39mcallable\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[39mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 183\u001b[0m         \u001b[39mcallable\u001b[39;49m()\n\u001b[0;32m    184\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m         \u001b[39m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[0;32m    186\u001b[0m         \u001b[39m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[0;32m    187\u001b[0m         \u001b[39m# else here if this ends up being important.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m         \u001b[39mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[1;32mc:\\Users\\ciara\\anaconda3\\envs\\Monai\\lib\\site-packages\\torch\\cuda\\random.py:111\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[1;34m()\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(device_count()):\n\u001b[0;32m    110\u001b[0m     default_generator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdefault_generators[i]\n\u001b[1;32m--> 111\u001b[0m     default_generator\u001b[39m.\u001b[39;49mmanual_seed(seed)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interact\n",
    "\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interact\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import Dropout2d\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    " \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Normalize\n",
    "from torchinfo import summary\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "np.random.seed(0) \n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# path para guardar o dataset\n",
    "PATH = './'\n",
    "PATH_TRAIN_CSV = './data/train.csv'\n",
    "PATH_TRAIN_IMG = './data/train_data.mat'\n",
    "PATH_TEST_CSV = './data/test.csv'\n",
    "PATH_TEST_IMG = './data/test_data.mat'\n",
    "\n",
    "BATCH_SIZE = 28\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Exploração e Preparação dos Dados\n",
    "\n",
    "### Visualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_mat(train_file,test_file):\n",
    "    train_mat = scipy.io.loadmat(train_file) \n",
    "    test_mat = scipy.io.loadmat(test_file) \n",
    "    # print(train_mat.keys())\n",
    "    # print(test_mat.keys())\n",
    "    train_np = np.array(train_mat['train_data']).transpose(2,0,1)\n",
    "    test_np = np.array(test_mat['test_data']).transpose(2,0,1)\n",
    "    # print(train_np.shape)\n",
    "    # print(test_np.shape)\n",
    "    return  train_np, test_np\n",
    "\n",
    "\n",
    "def load_data(path_train_csv, path_train_img, path_test_csv, path_test_img):\n",
    "    train_csv = pd.read_csv(path_train_csv, header=0)\n",
    "    test_csv = pd.read_csv(path_test_csv, header=0)\n",
    "    train_img, test_img = get_data_from_mat(path_train_img, path_test_img)\n",
    "    # train = train_csv + train_img\n",
    "    # test = test_csv + test_img\n",
    "    # return train, test\n",
    "    return train_csv, test_csv, train_img, test_img\n",
    "\n",
    "\n",
    "def visualize(image):\n",
    "    #plt.figure(\"sample\", (12, 6))\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image, cmap=\"gray\")    \n",
    "    #plt.subplot(1, 2, 2)\n",
    "    #plt.imshow(image, cmap=\"gray\")\n",
    "    plt.show()      \n",
    "\n",
    "def show_ds(ds):\n",
    "    print(\"ds shape:\",ds.shape)\n",
    "    print(\"ds max:\",np.max(ds))\n",
    "    print(\"ds min:\",np.min(ds))\n",
    "    print(\"ds average:\",np.average(ds))\n",
    "    @interact\n",
    "    def visualize_set(scan_index=(0,len(ds)-1)):\n",
    "        #print(scan_index)\n",
    "        visualize(ds[scan_index,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data de treino:\n",
      "      id  age  sex  education\n",
      "0      1   13    1          7\n",
      "1      2   14    0          8\n",
      "2      3   15    1          9\n",
      "3      4   15    1          9\n",
      "4      5   15    1          9\n",
      "..   ...  ...  ...        ...\n",
      "107  108   77    1          4\n",
      "108  109   67    0          4\n",
      "109  110   55    0          4\n",
      "110  111   76    1          3\n",
      "111  112   69    0          4\n",
      "\n",
      "[112 rows x 4 columns]\n",
      "ds shape: (112, 90, 90)\n",
      "ds max: 1.0\n",
      "ds min: 0.0\n",
      "ds average: 0.024116160549305543\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c220ce4eeb46548e187bdc8a38ece8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=55, description='scan_index', max=111), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data de Teste:\n",
      "    id  sex  education\n",
      "0    1    0         13\n",
      "1    2    0         11\n",
      "2    3    1          9\n",
      "3    4    1         13\n",
      "4    5    0         12\n",
      "5    6    0         17\n",
      "6    7    0          9\n",
      "7    8    0          4\n",
      "8    9    1          9\n",
      "9   10    1          4\n",
      "10  11    1         14\n",
      "11  12    0          9\n",
      "12  13    1          2\n",
      "13  14    1          5\n",
      "14  15    1          9\n",
      "15  16    1         11\n",
      "16  17    1          9\n",
      "17  18    0         17\n",
      "18  19    1         15\n",
      "19  20    1         14\n",
      "20  21    1          4\n",
      "21  22    0          4\n",
      "22  23    1          4\n",
      "23  24    0          0\n",
      "24  25    1          2\n",
      "25  26    1          4\n",
      "26  27    1          3\n",
      "27  28    1          4\n",
      "ds shape: (28, 90, 90)\n",
      "ds max: 1.0\n",
      "ds min: 0.0\n",
      "ds average: 0.024994026906171023\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3a73589fda4645ba41ae53448c73b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=13, description='scan_index', max=27), Output()), _dom_classes=('widget-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv, test_csv, train_img, test_img = load_data(PATH_TRAIN_CSV, PATH_TRAIN_IMG, PATH_TEST_CSV, PATH_TEST_IMG)\n",
    "\n",
    "print(\"Data de treino:\")\n",
    "print(train_csv)\n",
    "show_ds(train_img)\n",
    "print(\"Data de Teste:\")\n",
    "print(test_csv)\n",
    "show_ds(test_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_sex(csv):\n",
    "    female = csv['sex']\n",
    "    male = []\n",
    "    for person in female:\n",
    "        if person==1:\n",
    "            male.append(0)\n",
    "        else:\n",
    "            male.append(1)\n",
    "    csv.drop('sex', axis='columns', inplace=True)\n",
    "    csv['Female']=female\n",
    "    csv['Male']=male\n",
    "    return csv\n",
    "    \n",
    "def img_to_list(img):\n",
    "    tamanho = len(img)\n",
    "    lista = []\n",
    "    # triangular inferior sem diagonal\n",
    "    for linha in range(tamanho):\n",
    "        for coluna in range(linha):\n",
    "            lista.append(img[linha][coluna])\n",
    "    return lista\n",
    "\n",
    "def imgs_to_matrix(imgs):\n",
    "    matrix = []\n",
    "    for img in imgs:\n",
    "        matrix.append(img_to_list(img))\n",
    "    return matrix\n",
    "\n",
    "def remove_null_columns(matrix1, matrix2):\n",
    "    columns_to_remove = []\n",
    "    m1_row_len = len(matrix1)\n",
    "    m2_row_len = len(matrix2)\n",
    "    column_len = len(matrix1[0])\n",
    "    for column in range(column_len):\n",
    "        all_zero = True\n",
    "        for row in range(m1_row_len):\n",
    "            if matrix1[row][column]!=0:\n",
    "                all_zero=False\n",
    "        for row in range(m2_row_len):\n",
    "            if matrix2[row][column]!=0:\n",
    "                all_zero=False\n",
    "        if all_zero:\n",
    "            columns_to_remove.append(column)\n",
    "\n",
    "    brain_activity_index = list(range(column_len))\n",
    "    for column in columns_to_remove[::-1]:\n",
    "        brain_activity_index.pop(column)\n",
    "        for line in range(m1_row_len):\n",
    "            matrix1[line].pop(column)\n",
    "        for line in range(m2_row_len):\n",
    "            matrix2[line].pop(column)\n",
    "    return matrix1, matrix2, brain_activity_index\n",
    "\n",
    "def join_data(train_csv, test_csv, train_img, test_img):\n",
    "    train_matrix = imgs_to_matrix(train_img)\n",
    "    test_matrix = imgs_to_matrix(test_img)\n",
    "    train_clean_matrix, test_clean_matrix, brain_activity_index = remove_null_columns(train_matrix, test_matrix)\n",
    "    train_data  = pd.concat([train_csv, pd.DataFrame(train_clean_matrix)], axis=1)\n",
    "    train_data .columns = list(train_csv.columns) + [f'rel-{brain_activity_index[i]}' for i in range(len(brain_activity_index))]\n",
    "    test_data = pd.concat([test_csv, pd.DataFrame(test_clean_matrix)], axis=1)\n",
    "    test_data.columns = list(test_csv.columns) + [f'rel-{brain_activity_index[i]}' for i in range(len(brain_activity_index))]\n",
    "    return train_data , test_data, brain_activity_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  age  education  Female  Male     rel-1  rel-3     rel-4     rel-5  \\\n",
      "0      1   13          7       1     0  0.131525    0.0  0.136950  0.000000   \n",
      "1      2   14          8       0     1  0.117704    0.0  0.132998  0.037714   \n",
      "2      3   15          9       1     0  0.155806    0.0  0.165429  0.022278   \n",
      "3      4   15          9       1     0  0.145214    0.0  0.162493  0.000000   \n",
      "4      5   15          9       1     0  0.161360    0.0  0.172043  0.017686   \n",
      "..   ...  ...        ...     ...   ...       ...    ...       ...       ...   \n",
      "107  108   77          4       1     0  0.215767    0.0  0.184942  0.019446   \n",
      "108  109   67          4       0     1  0.143005    0.0  0.124350  0.000000   \n",
      "109  110   55          4       0     1  0.116085    0.0  0.156406  0.020947   \n",
      "110  111   76          3       1     0  0.156654    0.0  0.166613  0.046464   \n",
      "111  112   69          4       0     1  0.114586    0.0  0.128877  0.045583   \n",
      "\n",
      "        rel-8  ...  rel-3975  rel-3977  rel-3979  rel-3981  rel-3989  \\\n",
      "0    0.146309  ...  0.000000  0.000000  0.000000  0.014927  0.000000   \n",
      "1    0.113425  ...  0.000000  0.000000  0.000000  0.031811  0.000000   \n",
      "2    0.096080  ...  0.000000  0.000000  0.000000  0.021235  0.018050   \n",
      "3    0.124115  ...  0.000000  0.000000  0.000000  0.015130  0.000000   \n",
      "4    0.099488  ...  0.000000  0.000000  0.000000  0.016533  0.000000   \n",
      "..        ...  ...       ...       ...       ...       ...       ...   \n",
      "107  0.109972  ...  0.033167  0.015108  0.016434  0.056483  0.000000   \n",
      "108  0.090189  ...  0.000000  0.013166  0.029519  0.051964  0.000000   \n",
      "109  0.122589  ...  0.000000  0.000000  0.000000  0.034193  0.010498   \n",
      "110  0.091244  ...  0.000000  0.000000  0.000000  0.051497  0.012697   \n",
      "111  0.124734  ...  0.000000  0.000000  0.045683  0.028919  0.000000   \n",
      "\n",
      "     rel-3993  rel-3997  rel-3999  rel-4001  rel-4003  \n",
      "0    0.000000  0.000000  0.000000  0.585006  0.280606  \n",
      "1    0.000000  0.000000  0.000000  0.599437  0.207478  \n",
      "2    0.000000  0.000000  0.000000  0.630374  0.246472  \n",
      "3    0.000000  0.000000  0.000000  0.562505  0.287888  \n",
      "4    0.000000  0.000000  0.000000  0.564043  0.234284  \n",
      "..        ...       ...       ...       ...       ...  \n",
      "107  0.000000  0.000000  0.011150  0.660292  0.302675  \n",
      "108  0.013098  0.011171  0.019141  0.630415  0.204125  \n",
      "109  0.000000  0.000000  0.000000  0.574355  0.246784  \n",
      "110  0.019894  0.010225  0.000000  0.631057  0.216259  \n",
      "111  0.000000  0.024996  0.000000  0.655354  0.274812  \n",
      "\n",
      "[112 rows x 1207 columns]\n",
      "    id  education  Female  Male     rel-1     rel-3     rel-4     rel-5  \\\n",
      "0    1         13       0     1  0.140891  0.000000  0.158141  0.034232   \n",
      "1    2         11       0     1  0.147297  0.000000  0.155310  0.022638   \n",
      "2    3          9       1     0  0.091724  0.000000  0.117124  0.036960   \n",
      "3    4         13       1     0  0.095972  0.000000  0.139443  0.043691   \n",
      "4    5         12       0     1  0.129573  0.000000  0.156720  0.014294   \n",
      "5    6         17       0     1  0.142985  0.000000  0.183126  0.036850   \n",
      "6    7          9       0     1  0.131228  0.000000  0.175776  0.089642   \n",
      "7    8          4       0     1  0.101044  0.000000  0.133913  0.122353   \n",
      "8    9          9       1     0  0.230942  0.000000  0.301362  0.074309   \n",
      "9   10          4       1     0  0.134479  0.000000  0.213318  0.056141   \n",
      "10  11         14       1     0  0.189829  0.000000  0.204577  0.010921   \n",
      "11  12          9       0     1  0.185456  0.000000  0.168654  0.000000   \n",
      "12  13          2       1     0  0.134865  0.000000  0.145524  0.048349   \n",
      "13  14          5       1     0  0.108800  0.000000  0.153185  0.022882   \n",
      "14  15          9       1     0  0.159263  0.000000  0.158870  0.035078   \n",
      "15  16         11       1     0  0.181882  0.000000  0.250783  0.027103   \n",
      "16  17          9       1     0  0.173154  0.000000  0.141448  0.000000   \n",
      "17  18         17       0     1  0.139383  0.000000  0.189371  0.033366   \n",
      "18  19         15       1     0  0.135308  0.000000  0.142088  0.011406   \n",
      "19  20         14       1     0  0.117093  0.000000  0.135168  0.000000   \n",
      "20  21          4       1     0  0.203059  0.018586  0.180570  0.104014   \n",
      "21  22          4       0     1  0.084421  0.000000  0.154965  0.034056   \n",
      "22  23          4       1     0  0.192080  0.000000  0.210771  0.083894   \n",
      "23  24          0       0     1  0.154142  0.000000  0.168493  0.000000   \n",
      "24  25          2       1     0  0.227324  0.000000  0.231086  0.010481   \n",
      "25  26          4       1     0  0.179663  0.013680  0.163752  0.085185   \n",
      "26  27          3       1     0  0.193464  0.000000  0.251571  0.056901   \n",
      "27  28          4       1     0  0.122592  0.000000  0.164023  0.050183   \n",
      "\n",
      "       rel-8    rel-13  ...  rel-3975  rel-3977  rel-3979  rel-3981  rel-3989  \\\n",
      "0   0.125302  0.100274  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1   0.137629  0.092260  ...  0.000000  0.000000  0.000000  0.013910  0.000000   \n",
      "2   0.116989  0.104919  ...  0.000000  0.000000  0.000000  0.047666  0.010004   \n",
      "3   0.087918  0.126898  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4   0.095124  0.119225  ...  0.000000  0.000000  0.000000  0.015233  0.000000   \n",
      "5   0.091377  0.087207  ...  0.000000  0.000000  0.000000  0.010627  0.000000   \n",
      "6   0.123222  0.104854  ...  0.000000  0.000000  0.020643  0.036057  0.000000   \n",
      "7   0.108414  0.111986  ...  0.000000  0.000000  0.011329  0.023783  0.010706   \n",
      "8   0.065176  0.172441  ...  0.013943  0.040184  0.041840  0.039660  0.000000   \n",
      "9   0.084780  0.092307  ...  0.010035  0.000000  0.000000  0.013395  0.018347   \n",
      "10  0.111955  0.137713  ...  0.059839  0.000000  0.000000  0.086756  0.000000   \n",
      "11  0.120459  0.099187  ...  0.000000  0.000000  0.016020  0.024357  0.021780   \n",
      "12  0.101788  0.091091  ...  0.000000  0.022555  0.010633  0.029756  0.012671   \n",
      "13  0.088783  0.098697  ...  0.000000  0.000000  0.000000  0.018988  0.000000   \n",
      "14  0.107662  0.067334  ...  0.000000  0.000000  0.000000  0.057889  0.000000   \n",
      "15  0.105886  0.089768  ...  0.000000  0.000000  0.000000  0.049957  0.000000   \n",
      "16  0.087167  0.074704  ...  0.000000  0.000000  0.000000  0.017929  0.000000   \n",
      "17  0.101199  0.095522  ...  0.000000  0.000000  0.000000  0.030575  0.000000   \n",
      "18  0.133902  0.110800  ...  0.000000  0.000000  0.000000  0.017787  0.000000   \n",
      "19  0.088000  0.067355  ...  0.000000  0.000000  0.000000  0.050251  0.000000   \n",
      "20  0.126438  0.083578  ...  0.000000  0.017215  0.016428  0.023965  0.018130   \n",
      "21  0.127228  0.099905  ...  0.000000  0.017495  0.000000  0.091617  0.000000   \n",
      "22  0.110031  0.134561  ...  0.013666  0.042774  0.000000  0.126271  0.000000   \n",
      "23  0.094874  0.081863  ...  0.000000  0.000000  0.000000  0.033486  0.000000   \n",
      "24  0.099137  0.135413  ...  0.023205  0.000000  0.011331  0.088008  0.019708   \n",
      "25  0.160272  0.098753  ...  0.000000  0.000000  0.000000  0.075546  0.024103   \n",
      "26  0.112662  0.122816  ...  0.000000  0.016901  0.011435  0.048129  0.011214   \n",
      "27  0.085027  0.061122  ...  0.000000  0.000000  0.000000  0.025536  0.000000   \n",
      "\n",
      "    rel-3993  rel-3997  rel-3999  rel-4001  rel-4003  \n",
      "0   0.000000  0.000000  0.000000  0.612109  0.193069  \n",
      "1   0.000000  0.000000  0.000000  0.635466  0.275949  \n",
      "2   0.000000  0.000000  0.000000  0.577096  0.260915  \n",
      "3   0.000000  0.000000  0.000000  0.535117  0.198058  \n",
      "4   0.000000  0.000000  0.000000  0.590000  0.266638  \n",
      "5   0.000000  0.000000  0.000000  0.702736  0.267522  \n",
      "6   0.000000  0.000000  0.000000  0.612072  0.282661  \n",
      "7   0.000000  0.000000  0.014537  0.611550  0.291660  \n",
      "8   0.000000  0.011865  0.000000  0.608007  0.278882  \n",
      "9   0.013312  0.024165  0.000000  0.633834  0.284398  \n",
      "10  0.000000  0.010140  0.000000  0.662728  0.312695  \n",
      "11  0.000000  0.021331  0.018617  0.674813  0.441362  \n",
      "12  0.000000  0.000000  0.000000  0.583719  0.292009  \n",
      "13  0.000000  0.000000  0.000000  0.600286  0.286279  \n",
      "14  0.000000  0.000000  0.000000  0.555549  0.204871  \n",
      "15  0.000000  0.000000  0.000000  0.589784  0.310762  \n",
      "16  0.000000  0.000000  0.000000  0.576170  0.248499  \n",
      "17  0.000000  0.000000  0.000000  0.670338  0.232758  \n",
      "18  0.000000  0.000000  0.000000  0.646140  0.276538  \n",
      "19  0.000000  0.000000  0.000000  0.640091  0.320452  \n",
      "20  0.020956  0.000000  0.010584  0.684640  0.240465  \n",
      "21  0.000000  0.000000  0.016944  0.640797  0.249482  \n",
      "22  0.000000  0.000000  0.000000  0.654685  0.250583  \n",
      "23  0.000000  0.000000  0.047760  0.632460  0.325999  \n",
      "24  0.000000  0.011046  0.000000  0.693522  0.217447  \n",
      "25  0.000000  0.000000  0.000000  0.673725  0.213339  \n",
      "26  0.015723  0.000000  0.012270  0.602484  0.222229  \n",
      "27  0.000000  0.014708  0.000000  0.596880  0.259705  \n",
      "\n",
      "[28 rows x 1206 columns]\n"
     ]
    }
   ],
   "source": [
    "train_csv, test_csv, train_img, test_img = load_data(PATH_TRAIN_CSV, PATH_TRAIN_IMG, PATH_TEST_CSV, PATH_TEST_IMG)\n",
    "rain_csv = fix_sex(train_csv)\n",
    "test_csv = fix_sex(test_csv)\n",
    "train_data, test_data, brain_activity_index = join_data(train_csv, test_csv, train_img, test_img)\n",
    "print(train_data)\n",
    "print(test_data)\n",
    "train_data= train_data.drop('id', axis=1)\n",
    "test_data= test_data.drop('id', axis=1)\n",
    "train_data.to_csv('./data/train_joined.csv', index=False)\n",
    "test_data.to_csv('./data/test_joined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar as funções de transformação\n",
    "train_transform = Compose(\n",
    "        [ToTensor(), \n",
    "         Normalize(mean=(0.1307,), std=(0.3081,)) # parâmetros por canal da imagem, image = (image - mean) / std\n",
    "        ])\n",
    "test_transform = Compose(\n",
    "        [ToTensor(), \n",
    "         Normalize(mean=(0.1307,), std=(0.3081,)) # parâmetros por canal da imagem, image = (image - mean) / std\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buscar o dataset utilizando os CSVs e uma classe para o dataset\n",
    "\n",
    "# definição classe para o dataset\n",
    "class CSVDataset(Dataset):\n",
    "  # ler o dataset\n",
    "  def __init__(self, path, transform=None):\n",
    "    self.transform = transform\n",
    "    # ler o ficheiro csv para um dataframe\n",
    "    df_set = pd.read_csv(path, header=0)\n",
    "    # separar os inputs e os outputs\n",
    "    self.x = df_set.values[:, 1:]\n",
    "    self.y = df_set.values[:, 0]\n",
    "\n",
    "    # garantir que os inputs e labels sejam floats\n",
    "    # self.x = self.x.astype('float32')\n",
    "    # self.y = self.y.astype('long')\n",
    "    #print(self.x.shape)\n",
    "    #print(self.y.shape)\n",
    "        \n",
    "  # número de casos no dataset\n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "\n",
    "  # retornar um caso\n",
    "  def __getitem__(self, idx):\n",
    "    label = self.y[idx]\n",
    "    image = self.x[idx]       \n",
    "    if self.transform is not None:\n",
    "      image = self.transform(image)\n",
    "    return image, label\n",
    "    \n",
    "  # retornar índices para casos de treino e de teste em formato imagem\n",
    "  def get_TensorDataset(self):\n",
    "    x = self.x.reshape(len(self.x), 1, 1205)\n",
    "    xmax, xmin = x.max(), x.min()\n",
    "    x = (x - xmin)/(xmax - xmin)\n",
    "    x  = torch.from_numpy(np.array(x)).float()\n",
    "    y  = torch.from_numpy(np.array(self.y)).type(torch.LongTensor)\n",
    "    cases = torch.utils.data.TensorDataset(x,y)\n",
    "    return cases \n",
    "  \n",
    "  def get_TensorDataset_test(self):\n",
    "    x = self.x.reshape(len(self.x), 1, 1204)\n",
    "    xmax, xmin = x.max(), x.min()\n",
    "    x = (x - xmin)/(xmax - xmin)\n",
    "    x  = torch.from_numpy(np.array(x)).float()\n",
    "    y  = torch.from_numpy(np.array(self.y)).type(torch.LongTensor)\n",
    "    cases = torch.utils.data.TensorDataset(x,y)\n",
    "    return cases \n",
    "\n",
    "#com holdout\n",
    "def prepare_data_loaders(path_train, path_test):\n",
    "  train_data = CSVDataset(path_train,transform=train_transform)\n",
    "  test_data = CSVDataset(path_test,transform=test_transform)\n",
    "  train_data = train_data.get_TensorDataset()\n",
    "  test_data = test_data.get_TensorDataset_test()\n",
    "  train_size = int(0.8 * len(train_data))\n",
    "  val_size = len(train_data) - train_size\n",
    "  train_data, validation = random_split(train_data, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "  train_dl = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "  val_dl = DataLoader(validation, batch_size=BATCH_SIZE, shuffle=True)\n",
    "  test_dl = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "  train_dl_all = DataLoader(train_data, batch_size=len(train_data), shuffle=False)\n",
    "  val_dl_all = DataLoader(validation, batch_size=len(validation), shuffle=True)\n",
    "  test_dl_all = DataLoader(test_data, batch_size=len(test_data), shuffle=False)\n",
    "  return train_dl, val_dl, test_dl, train_dl_all, val_dl_all, test_dl_all\n",
    "\n",
    "# preparar os dados\n",
    "path_train = './data/train_joined.csv'\n",
    "path_test = './data/test_joined.csv'\n",
    "train_dl, val_dl, test_dl, train_dl_all, val_dl_all, test_dl_all = prepare_data_loaders(path_train, path_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Definir o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNNModel_2                               [28, 10]                  --\n",
      "├─Sequential: 1-1                        [28, 16, 13, 13]          --\n",
      "│    └─Conv2d: 2-1                       [28, 16, 26, 26]          160\n",
      "│    └─ReLU: 2-2                         [28, 16, 26, 26]          --\n",
      "│    └─MaxPool2d: 2-3                    [28, 16, 13, 13]          --\n",
      "├─Sequential: 1-2                        [28, 32, 5, 5]            --\n",
      "│    └─Conv2d: 2-4                       [28, 32, 11, 11]          4,640\n",
      "│    └─ReLU: 2-5                         [28, 32, 11, 11]          --\n",
      "│    └─MaxPool2d: 2-6                    [28, 32, 5, 5]            --\n",
      "├─Linear: 1-3                            [28, 10]                  8,010\n",
      "==========================================================================================\n",
      "Total params: 12,810\n",
      "Trainable params: 12,810\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 18.97\n",
      "==========================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 3.29\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 3.43\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# CNN Model2: Sequential (Conv, ReLU, MaxPool), Sequential, Linear\n",
    "class CNNModel_2(Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel_2, self).__init__()\n",
    "        self.layer1 = Sequential(Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=0),\n",
    "                                 ReLU(),\n",
    "                                 MaxPool2d(kernel_size=2)\n",
    "                                )\n",
    "        self.layer2 = Sequential(Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0),\n",
    "                                 ReLU(),\n",
    "                                 MaxPool2d(kernel_size=2)\n",
    "                                )       \n",
    "        self.fc1 = Linear(in_features=32 * 5 * 5, out_features=10)  # Fully connected 1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1) #Flatten\n",
    "        out = self.fc1(out) #Dense\n",
    "        return out\n",
    "    \n",
    "model = CNNModel_2()\n",
    "print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0)) #verbose=2 Show weight and bias layers in full detail\n",
    "    \n",
    "# CNN Model4: Sequential (Conv, BatchNorm, ReLU, MaxPool, Dropout), Linear, Linear\n",
    "# class CNNModel_4(Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNNModel_4, self).__init__()\n",
    "#         self.layer1 = Sequential(nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=0),\n",
    "#                                     BatchNorm2d(32),\n",
    "#                                     ReLU(),\n",
    "#                                     MaxPool2d(2),\n",
    "#                                     Dropout2d(0.2)\n",
    "#                                     )\n",
    "#         self.fc1 = Linear(in_features=BATCH_SIZE*12*12, out_features=128) # 16928\n",
    "#         self.fc2 = Linear(in_features=128, out_features=10)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out = self.layer1(x)\n",
    "#         out = out.view(out.size(0), -1)\n",
    "#         out = self.fc1(out)\n",
    "#         out = self.fc2(out)\n",
    "#         return out\n",
    "    \n",
    "# model = CNNModel_4()\n",
    "# print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0)) #verbose=2 Show weight and bias layers in full detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleRowCNN(Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SingleRowCNN, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv1d(in_channels=input_size, out_channels=16, kernel_size=3)\n",
    "\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "        self.fc = nn.Linear(19248, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layer\n",
    "        x = self.conv(x)\n",
    "\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "input_size = 1  # Number of features in the input data\n",
    "num_classes = 10  # Number of output classes\n",
    "\n",
    "\n",
    "model = SingleRowCNN(input_size, num_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Treinar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(h5_file, train_dl, val_dl, model, criterion, optimizer):\n",
    "    liveloss = PlotLosses()\n",
    "    for epoch in range(EPOCHS):\n",
    "        logs = {} # para o livelossplot\n",
    "        # Train phase\n",
    "        model.train() \n",
    "        running_loss  = 0.0\n",
    "        running_corrects  = 0.0\n",
    "        for batch_i, (inputs, labels) in enumerate(train_dl): \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.detach() * inputs.size(0)\n",
    "            #acc = accuracy_score(labels.numpy(), np.argmax(outputs.detach().numpy(), axis=1))\n",
    "            _, preds = torch.max(outputs, 1) # Get predictions from the maximum value\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(train_dl.dataset)\n",
    "        epoch_acc = running_corrects.float() / len(train_dl.dataset)\n",
    "        logs['loss'] = epoch_loss.item()\n",
    "        logs['accuracy'] = epoch_acc.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss  = 0.0\n",
    "        running_corrects  = 0.0\n",
    "        for inputs, labels in val_dl: \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.detach() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1) # Get predictions from the maximum value\n",
    "            #acc = accuracy_score(labels.numpy(), np.argmax(outputs.detach().numpy(), axis=1))\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(val_dl.dataset)\n",
    "        epoch_acc = running_corrects.float() / len(val_dl.dataset)\n",
    "        logs['val_loss'] = epoch_loss.item()\n",
    "        logs['val_accuracy'] = epoch_acc.item()\n",
    "        #print(f'Epoch {epoch:03}: | Loss: {epoch_loss/len(train_dl):.5f} | Acc: {epoch_acc/len(train_dl):.3f}')      \n",
    "        liveloss.update(logs)\n",
    "        liveloss.send()\n",
    "    torch.save(model,h5_file) # para gravar o modelo no final do treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CNNModel_2 ################\n",
    "# model = CNNModel_2()\n",
    "model.cuda()\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ciara\\Desktop\\imag-deep-learning\\cnn-multiclass.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ciara/Desktop/imag-deep-learning/cnn-multiclass.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m#optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ciara/Desktop/imag-deep-learning/cnn-multiclass.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m starttime \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ciara/Desktop/imag-deep-learning/cnn-multiclass.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m train_model(\u001b[39m'\u001b[39;49m\u001b[39mCNNModel_2.pth\u001b[39;49m\u001b[39m'\u001b[39;49m, train_dl, val_dl, model, criterion, optimizer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ciara/Desktop/imag-deep-learning/cnn-multiclass.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m endtime \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ciara/Desktop/imag-deep-learning/cnn-multiclass.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTempo gasto: \u001b[39m\u001b[39m{\u001b[39;00mendtime\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstarttime\u001b[39m}\u001b[39;00m\u001b[39m segundos\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\ciara\\Desktop\\imag-deep-learning\\cnn-multiclass.ipynb Cell 18\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(h5_file, train_dl, val_dl, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ciara/Desktop/imag-deep-learning/cnn-multiclass.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m running_corrects  \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ciara/Desktop/imag-deep-learning/cnn-multiclass.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_i, (inputs, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dl): \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ciara/Desktop/imag-deep-learning/cnn-multiclass.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ciara/Desktop/imag-deep-learning/cnn-multiclass.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ciara/Desktop/imag-deep-learning/cnn-multiclass.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# treino do modelo CNNModel_2\n",
    "# for batch in train_dl:\n",
    "#     print(batch)\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "criterion = CrossEntropyLoss() # neste caso implementa a sparse_categorical_crossentropy #nn.CrossEntropyLoss accepts ground truth labels directly as integers #in [0, N_CLASSES[ (no need to onehot encode the labels)\n",
    "optimizer = SGD(model.parameters(), lr=LEARNING_RATE) \n",
    "#optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "starttime = time.perf_counter()\n",
    "train_model('CNNModel_2.pth', train_dl, val_dl, model, criterion, optimizer)\n",
    "endtime = time.perf_counter()\n",
    "print(f\"Tempo gasto: {endtime - starttime} segundos\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Avaliar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Testar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
